#!/usr/bin/env python3
import os
import re
import base64
import threading
import json
import openai
import rclpy
from rclpy.node import Node
from std_msgs.msg import String, Bool


class GPTImageRobotController(Node):
    def __init__(self):
        super().__init__('gpt_image_robot_controller')

        # OpenAI API í‚¤
        openai.api_key = os.getenv("GPT_API_KEY")

        # âœ… ëª¨í„° ì œì–´ í† í”½: /cmd_motor (ë¬¸ìì—´: forward/backward/left/right/stop)
        self.cmd_motor_pub = self.create_publisher(String, '/cmd_motor', 10)

        # thrust_control ìª½ì—ì„œ "ì§€ê¸ˆ ëª¨í„°ê°€ ë°”ì˜ë‹¤" ìƒíƒœë¥¼ ì•Œë ¤ì¤„ í† í”½ (ì˜µì…˜)
        self.thrust_busy_sub = self.create_subscription(
            Bool, 'thrust_busy', self.thrust_busy_callback, 10
        )

        # ê²½ë¡œ ëª¨ë“œ ìƒíƒœ ê´€ë¦¬
        self.in_path_mode = False
        self.path_plan = []
        self.current_step = 0

        # ìƒíƒœ í”Œë˜ê·¸
        self.thrust_is_busy = False
        self.processing = False

        # ì£¼ê¸°ì ìœ¼ë¡œ main_processë¥¼ í˜¸ì¶œ (ë‹¨, busy ì•„ë‹ˆê³  processing ì•„ë‹ ë•Œë§Œ)
        self.timer = self.create_timer(5.0, self.timer_callback)

    def thrust_busy_callback(self, msg: Bool):
        self.thrust_is_busy = msg.data

    def timer_callback(self):
        # ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜, ëª¨í„° ìª½ì—ì„œ busyë¼ê³  ì•Œë ¤ì£¼ë©´ ìŠ¤í‚µ
        if self.processing or self.thrust_is_busy:
            return
        self.processing = True
        threading.Thread(target=self.main_process, daemon=True).start()

    # âœ… w/a/s/d ë˜ëŠ” "stop" â†’ /cmd_motorìš© ë¬¸ìì—´ë¡œ ë§¤í•‘í•´ì„œ publish
    def publish_motor_command(self, key: str):
        """
        key: 'w', 'a', 's', 'd' ë˜ëŠ” 'stop'
        /cmd_motor ì— forward/backward/left/right/stop ë¬¸ìì—´ì„ publish
        """
        key = key.strip().lower()
        mapping = {
            'w': 'forward',
            's': 'backward',
            'a': 'left',
            'd': 'right',
            'stop': 'stop',
        }
        cmd = mapping.get(key, None)
        if cmd is None:
            self.get_logger().warn(f"[CMD MAP] Unknown key '{key}', ignoring.")
            return

        self.get_logger().info(f"[CMD PUB] /cmd_motor -> {cmd}")
        self.cmd_motor_pub.publish(String(data=cmd))

    def get_latest_image_path(self):
        """
        ~/saved_images ì•ˆì—ì„œ saved_image_ìˆ«ì.(png|jpg|jpeg) ì¤‘
        ê°€ì¥ ë²ˆí˜¸ê°€ í° íŒŒì¼ì„ ì°¾ì•„ì„œ ê²½ë¡œ ë°˜í™˜
        """
        image_dir = os.path.expanduser('~/saved_images')
        # ğŸ”§ image_saverê°€ jpgë¡œ ì €ì¥í•˜ë¯€ë¡œ í™•ì¥ìë“¤ì„ ëª¨ë‘ í—ˆìš©
        pattern = re.compile(r'saved_image_(\d+)\.jpg')
        try:
            files = os.listdir(image_dir)
            numbered_files = []
            for f in files:
                m = pattern.fullmatch(f)
                if m:
                    idx = int(m.group(1))
                    numbered_files.append((idx, f))
            if not numbered_files:
                return None
            latest_file = max(numbered_files)[1]
            return os.path.join(image_dir, latest_file)
        except Exception as e:
            self.get_logger().warn(f"[IMAGE] get_latest_image_path error: {e}")
            return None

    def image_to_base64(self, image_path):
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode('utf-8')

    def request_threat_assessment_from_image(self, image_data, image_path):
        prompt = (
            "You are the navigation system of an autonomous water drone.\n"
            "The drone is twin-hull (catamaran-style), 2.5m wide, 5m long, and 1.5m high.\n"
            "The camera is mounted 0.85 meters from the front and 1.1 meters above the water surface.\n\n"
            "Your task is to decide whether the drone should STOP or continue MOVE, based on obstacles and the yellow duck position (if visible).\n\n"
            "Follow these rules:\n"
            "- If any object (e.g., buoy, obstacle **except duck**) is directly in front of the drone and appears within approximately 2 meters, respond with \"stop\".\n"
            "- If the yellow duck is centered and very close (within ~2 meters), also respond with \"stop\".\n"
            "- If the path ahead looks clear, even if the duck is not visible, respond with \"move\".\n"
            "- If you are unsure, prefer \"move\" over \"stop\".\n\n"
            "Do not be overly cautious. Base your judgment on clear visual threat of collision.\n\n"
            "Respond ONLY with the following JSON format (no explanations or markdown):\n"
            "{\n"
            "  \"decision\": \"move\" or \"stop\"\n"
            "}"
        )

        self.get_logger().info(f"###############[THREAT CHECK] {image_path}###############")

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url",
                         "image_url": {"url": "data:image/jpeg;base64," + image_data}},
                        {"type": "text", "text": (
                            "Is it safe for the drone to continue moving forward?\n"
                            "Evaluate based only on this image.\n"
                        )}
                    ]
                }
            ],
            max_tokens=50,
            temperature=0.3,
            top_p=0.8
        )

        result_text = response.choices[0].message.content.strip()
        self.get_logger().info(f"[THREAT CHECK RESPONSE] {result_text}")

        try:
            if result_text.startswith("```"):
                result_text = re.sub(r"```(json)?", "", result_text).strip()
                result_text = re.sub(r"```", "", result_text).strip()
            result = json.loads(result_text)
            decision = result.get("decision", "").strip().lower()
            if decision not in ["move", "stop"]:
                self.get_logger().warn(
                    f"[THREAT CHECK] Unexpected decision '{decision}', defaulting to 'stop'"
                )
                return "stop"
            return decision
        except Exception as e:
            self.get_logger().warn(f"[THREAT CHECK ERROR] {e}")
            return "stop"  # fallback for safety

    def request_decision_and_direction_from_image(self, image_data, image_path):
        self.get_logger().info(
            f"*****************************{image_path}*****************************"
        )
        prompt = (
            # (í”„ë¡¬í”„íŠ¸ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€)
            "You are the navigation system of an autonomous water drone.\n"
            "The drone is twin-hull (catamaran-style), 2.5m wide, 5m long, and 1.5m high.\n"
            "The camera is mounted 0.85 meters from the front and 1.1 meters above the water surface.\n"
            "The gray object you see underneath the image is the front of the drone engine. It's not an obstacle.\n"
            "The engine part is the front of the drone, and the width of the engine is equal to the total lateral length of the drone.\n\n"
            "Camera has a horizontal field of view (FOV) of 90Âº and a vertical FOV of 60Âº."
            "According to this, it would be left 45Âº if it was on the left-end and right 45Âº if it was on the right-end.\n"
            "The duck_position should describe where the yellow duck appears in the image using approximate angular position from the center.\n"
            "Use one of the following formats:\n"
            "   - \"left-30Âº\", \"left-15Âº\", \"center\", \"right-10Âº\", \"right-25Âº\"\n"
            "   - If no duck is visible, respond with:\n \"unknown\"\n"
            "Your task is to decide the next movement direction based on the current image and recent navigation history.\n\n"
            "Primary rules based on the current image:\n"
            "1. If there are not obstacles and yellow duck on image, rotate ('a' or 'd') to search the yellow duck.\n"
            "2. If there are not obstacles but the yellow duck is visible.:\n"
            "    2.1 - If the yellow duck is far, move forward ('w') to approach it.\n"
            "    2.2 - If the yellow duck is close, center the yellow duck in the view and stop.\n"
            "3. If there are obstacles on image and obstacles are far:\n"
            "    3.1 - If the yellow duck is not visible, move forward or rotate freely to search the yellow duck.\n"
            "    3.2 - If the yellow duck is visible, move forward in a direction that keeps distance from the obstacles while approaching the yellow duck.\n"
            "4. If there are obstacles on image and obstacles are close:\n"
            "    4.1 - If the yellow duck is not visible, rotate away from the nearest obstacle to find the yellow duck.\n"
            "    4.2 - If the yellow duck is far, move forward only in a direction that turns away from the obstacle.\n"
            "    4.3 - If the yellow duck is close, first adjust the drone to keep away from the obstacle, then rotate or move to center the yellow duck.\n"
            "5. If the yellow duck is centered and its distance is within 2 meters, stop.\n"
            "6. If you find a yellow duck, respond duck_found as true, otherwise false.\n\n"
            "Note: If \"duck_position\" is \"unknown\", then \"duck_found\" must be false.\n"
            "Respond strictly in the following JSON format:\n"
            "Do not include any explanations, markdown formatting, or code block markers like ```json. "
            "Output only the raw JSON object."
            "{\n"
            "  \"decision\": \"move\" or \"stop\",\n"
            "  \"direction\": \"w\" or \"a\" or \"s\" or \"d\"\n"
            "  \"duck_found\": true or false\n"
            "  \"duck_position\": a string such as \"unknown\" or \"left-20Âº\" or \"right-10Âº\" or \"center\" \n"
            "}"
        )

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url",
                         "image_url": {"url": "data:image/jpeg;base64," + image_data}},
                        {"type": "text", "text": (
                            "I want to get to the yellow duck if it exists, while avoiding obstacles.\n"
                            "Only identify a yellow duck if it is clearly present in the image.\n"
                            "Do not assume a yellow duck is always there. "
                            "Use image contents to determine presence.\n"
                            "Place the yellow duck at the center-bottom of the image **only if found**.\n"
                        )}
                    ]
                }
            ],
            max_tokens=100,
            temperature=0.7,
            top_p=0.5
        )
        result_text = response.choices[0].message.content.strip()
        self.get_logger().info(f"GPT response: {result_text}")
        try:
            if result_text.startswith("```"):
                result_text = re.sub(r"```(json)?", "", result_text).strip()
                result_text = re.sub(r"```", "", result_text).strip()
            result = json.loads(result_text)
            return (
                result.get("decision", ""),
                result.get("direction", ""),
                result.get("duck_found", False),
                result.get("duck_position", "unknown"),
            )
        except Exception as e:
            self.get_logger().warn(f"[DECISION PARSE ERROR] {e}")
            return None, None, False, "unknown"

    def request_path_plan_from_image(self, image_data, image_path):
        self.get_logger().info(f"[PATH PLAN] From {image_path}")
        prompt = (
            # (í”„ë¡¬í”„íŠ¸ ì›ë¬¸ ìœ ì§€)
            "You are the navigation system of an autonomous water drone.\n"
            "The drone is twin-hull (catamaran-style), 2.5m wide, 5m long, and 1.5m high.\n"
            "The camera is mounted 0.85 meters from the front and 1.1 meters above the water surface.\n"
            "The gray object you see underneath the image is the front of the drone engine. It's not an obstacle.\n"
            "The engine part is the front of the drone, and the width of the engine is equal to the total lateral length of the drone.\n\n"
            "Camera has a horizontal field of view (FOV) of 90Âº and a vertical FOV of 60Âº. According to this, it would be left 45Âº if it was on the left-end and right 45Âº if it was on the right-end.\n"
            "All directional decisions (left/right) must be made based strictly on the image coordinates:\n"
            "- The left side of the image is 'left'.\n"
            "- The right side of the image is 'right'.\n"
            "Your task is to decide the next movement direction based on image\n"
            "Use the following rules:\n"
            "1. If there are no obstacles and the yellow duck is visible:\n"
            "    - If the yellow duck is on the right, rotate right ('d') until it is near the center, then move forward ('w').\n"
            "    - If the yellow duck is on the left, rotate left ('a') until it is near the center, then move forward ('w').\n"
            "    - Do not rotate in the opposite direction of the duck's position.\n"
            "2. If obstacles exist and are far:\n"
            "    - Prioritize approaching the duck while maintaining a safe path.\n"
            "3. If obstacles are close:\n"
            "    - Avoid obstacles using the opposite direction, then continue toward the duck.\n"
            "4. If the yellow duck is centered and within 2 meters, stop.\n\n"
            "Respond strictly in the following JSON format:\n"
            "Do not include any explanations, markdown formatting, or code block markers like ```json. "
            "Output only the raw JSON object."
            "{ \"path\": [\"a\", \"w\", \"w\"] }"
        )
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "image_url",
                         "image_url": {"url": "data:image/jpeg;base64," + image_data}},
                        {"type": "text", "text": (
                            "Make the decision for the drone to reach the yellow duck. Yellow duck is not an obstacle, so don't avoid it."
                            "Use image contents to determine presence.\n"
                            "Place the yellow duck at the center-bottom of the image\n"
                            "The rotation of direction doesn't necessarily have to be one. There's no problem with multiple times.\n"
                            "And it's also possible to move back through s.\n"
                        )}
                    ]
                }
            ],
            max_tokens=40,
            temperature=0.5,
            top_p=0.8
        )
        result_text = response.choices[0].message.content.strip()
        self.get_logger().info(f"[PATH PLAN RESPONSE]: {result_text}")
        try:
            if result_text.startswith("```"):
                result_text = re.sub(r"```(json)?", "", result_text).strip()
                result_text = re.sub(r"```", "", result_text).strip()
            result = json.loads(result_text)
            return result.get("path", [])
        except Exception as e:
            self.get_logger().error(f"[PATH PLAN ERROR] {e}")
            return []

    def main_process(self):
        try:
            # 1) ìµœì‹  ì´ë¯¸ì§€ ì°¾ê¸°
            image_path = self.get_latest_image_path()
            if not image_path or not os.path.exists(image_path):
                self.get_logger().warn("[IMAGE] No image found in ~/saved_images.")
                self.processing = False
                return

            # ğŸ‘‰ ì—¬ê¸°ì„œ ì–´ë–¤ ì´ë¯¸ì§€ë¥¼ ì¼ëŠ”ì§€ ë¡œê·¸ ë‚¨ê¹€
            self.get_logger().info(f"[IMAGE] Using latest image: {image_path}")

            image_data = self.image_to_base64(image_path)

            # =====================
            # PATH MODE
            # =====================
            if self.in_path_mode:
                if self.current_step >= len(self.path_plan):
                    self.get_logger().info(
                        "[PATH MODE] Path complete. Returning to normal mode."
                    )
                    self.in_path_mode = False
                    self.path_plan = []
                    self.current_step = 0
                    return

                # ìµœì‹  ì´ë¯¸ì§€ ë‹¤ì‹œ í™•ì¸ (ê²½ë¡œ ìˆ˜í–‰ ì¤‘ì´ë¼ë„ ìµœì‹  ìƒí™© ë°˜ì˜)
                image_path = self.get_latest_image_path()
                if not image_path or not os.path.exists(image_path):
                    self.get_logger().warn(
                        "[WARNING] No new image found during path execution."
                    )
                    self.in_path_mode = False
                    self.path_plan = []
                    self.current_step = 0
                    return

                self.get_logger().info(f"[IMAGE][PATH MODE] Using latest image: {image_path}")
                image_data = self.image_to_base64(image_path)
                
                # ìœ„í˜‘ ì²´í¬
                decision = self.request_threat_assessment_from_image(image_data, image_path)

                if decision == "stop":
                    self.get_logger().warn(
                        "[THREAT] GPT advised stop during path plan."
                    )
                    self.in_path_mode = False
                    self.path_plan = []
                    self.current_step = 0
                    # ëª¨í„°ë„ ì‹¤ì œë¡œ stop
                    self.publish_motor_command('stop')
                    return

                # path step ì‹¤í–‰
                direction_raw = self.path_plan[self.current_step]
                direction = str(direction_raw).strip().replace("'", "").replace('"', "")

                if direction in ['w', 'a', 's', 'd']:
                    self.get_logger().info(
                        f"[PATH MODE] Executing step {self.current_step + 1}: {direction}"
                    )
                    self.publish_motor_command(direction)
                    self.current_step += 1
                else:
                    self.get_logger().warn(
                        f"[PATH MODE] Invalid direction '{direction_raw}' at step {self.current_step}. Skipping."
                    )
                    self.current_step += 1

                return

            # =====================
            # NORMAL MODE
            # =====================
            decision, direction, duck_found, duck_position = \
                self.request_decision_and_direction_from_image(image_data, image_path)
            
            if duck_found:
                self.get_logger().info(
                    f"[INFO] Duck detected at {duck_position} â†’ switching to path planning."
                )
                self.in_path_mode = True
                
                image_path = self.get_latest_image_path()
                if not image_path or not os.path.exists(image_path):
                    self.get_logger().warn(
                        "[PATH MODE] No image available when starting path plan."
                    )
                    self.in_path_mode = False
                    return

                self.get_logger().info(f"[IMAGE][PATH START] Using latest image: {image_path}")
                image_data = self.image_to_base64(image_path)
                
                self.path_plan = self.request_path_plan_from_image(image_data, image_path)
                self.current_step = 0
           
                if self.path_plan and self.path_plan[0] != "stop":
                    first = str(self.path_plan[0]).strip().replace("'", "").replace('"', "")
                    self.publish_motor_command(first)
                    self.get_logger().info(
                        f"[PATH MODE] Immediately executing step 1: {first}"
                    )
                    self.current_step += 1
                return

            # ğŸ” ì¼ë°˜ ëª¨ë“œ: move/stop ê²°ì •
            if decision == "stop":
                self.publish_motor_command('stop')
            elif decision == "move" and direction in ['w', 'a', 's', 'd']:
                self.publish_motor_command(direction)

        except Exception as e:
            self.get_logger().error(f"[ERROR] {e}")
        finally:
            self.processing = False


def main(args=None):
    rclpy.init(args=args)
    node = GPTImageRobotController()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        # ì´ë¯¸ shutdown ëœ ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬
        try:
            rclpy.shutdown()
        except Exception:
            pass


if __name__ == '__main__':
    main()
